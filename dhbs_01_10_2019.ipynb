{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBArPEb8wmC6"
   },
   "source": [
    "# Introduction to Text-Fabric: the Hebrew Bible and the DSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A9sKJ79-2a8L"
   },
   "source": [
    "by Martijn Naaijer, September 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0y1UprBLxWIi"
   },
   "source": [
    "We are going to work with the ETCBC database using [Text-Fabric](https://annotation.github.io/text-fabric/) (or TF). TF is a Python package. This package is used for storing, querying and analyzing annotated textual data. The TF project started a few years ago with the Hebrew Bible, but in the meanwhile there is a whole range of [texts in various languages](https://annotation.github.io/text-fabric/About/Corpora/) covered by TF. It is a community driven project, so if you want, you can contribute to it yourself!\n",
    "\n",
    "In this course we work in the cloud. In this case, that means, that all the computations are done on a server of Google. If you want, you can also install it on your own machine. In that case you install [Anaconda](https://www.anaconda.com/distribution/#download-section), you open a Jupyter Notebook, and you can start coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With TF you can query the data in two ways. The first one is the pure Python approach. For this approach you need to write scripts in the Python programming language. This language is not difficult to learn, but you need a lot of practice to become fluent in it. \n",
    "The second approach is called Search. Search is a template based query language. In this tutorial we will use both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vqLgBo2AuTR"
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install the text-fabric software with the following shell command. In you work offline you need to do this only once, in the cloud(Google's colab), you have to install it at the start of every session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "colab_type": "code",
    "id": "uZFZXVp1w0Pq",
    "outputId": "96e42793-75df-4fcb-d318-5af1c1eaebe9"
   },
   "outputs": [],
   "source": [
    "!pip install text-fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6riHuTj2kHi"
   },
   "source": [
    "Now we have the TF software, but we still need the data, and activate the system. We do this with the TF incantation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output of the incantation you find some important links, such as [the feature documentation](https://etcbc.github.io/bhsa/features/0_home/), [the Search documentation](https://annotation.github.io/text-fabric/Use/Search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "-ePsBcNU1PIH",
    "outputId": "a6bf76d1-5341-451f-c49c-0de70af58e86"
   },
   "outputs": [],
   "source": [
    "from tf.app import use\n",
    "A = use('bhsa', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uX5AFfu3f6-"
   },
   "source": [
    "In the incantation \"bhsa\" stands for Biblia Hebraica Stuttgartensia Amstelodamensis, which is the electronic ETCBC edition of the MT, based on the fourth edition of the BHS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search BHSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with Search! First a simple Search query is formulated in which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "word vs=nif\n",
    "'''\n",
    "\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to see the whole clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "clause\n",
    "  word vs=qal # line starts with two spaces!\n",
    "'''\n",
    "\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we want more conditions to be satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "clause\n",
    "  word vs=qal nu=pl\n",
    "'''\n",
    "\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the clause has to occur in the book of Exodus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "book book=Exodus\n",
    "  clause\n",
    "    word vs=qal nu=pl\n",
    "'''\n",
    "\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course the qal verb occurs earlier in the clause than the name of Moses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "book book=Exodus\n",
    "  clause\n",
    "    word vs=qal \n",
    "    < word lex=MCH=/\n",
    "'''\n",
    "\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also search for text in the ETCBC transcription. Sometimes it is handy to search for specific lexemes (feature: lex). You can find all lexemes in etcbc transcription on [Shebanq](https://shebanq.ancient-data.org/hebrew/words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "clause\n",
    "  word lex=W\n",
    "  <: word lex=QR>[\n",
    "'''\n",
    "\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can also search for a concrete consonantal representation, with the feature g_cons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "clause\n",
    "  word g_cons=W\n",
    "  <: word g_cons=JQR>W\n",
    "'''\n",
    "\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "clause\n",
    "  word g_cons=W\n",
    "  <: word g_cons=JQR>W\n",
    "  \n",
    "'''\n",
    "\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have the \"raw\" results, use S.search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in S.search(query):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BHSA with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6MCwuDyn3M-s",
    "outputId": "a3506580-b44e-4c6f-fbe1-7d80f966a4ef"
   },
   "outputs": [],
   "source": [
    "for w in F.otype.s(\"word\"):\n",
    "  if F.lex.v(w) == \"HLK[\":\n",
    "    print(T.sectionFromNode(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ulpLCKCJ9BVF"
   },
   "source": [
    "It is nice to know where we can find the word הלך, but if we want to know more about these cases, we need to adapt the script a little bit. For instance, we want to know more about the morphology of the verb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rLwV4BXk9ArC",
    "outputId": "20846ae5-a906-4a8c-bb7e-bda2bf62daa0"
   },
   "outputs": [],
   "source": [
    "for w in F.otype.s(\"word\"):\n",
    "  if F.lex.v(w) == \"HLK[\":\n",
    "    print(T.sectionFromNode(w), F.vt.v(w), F.vs.v(w), F.gn.v(w), F.nu.v(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JwWj5Sep_aO0",
    "outputId": "4ecc9fde-092f-4e04-bd3b-08611c9cd872"
   },
   "outputs": [],
   "source": [
    "for w in F.otype.s(\"word\"):\n",
    "    \n",
    "  if F.lex.v(w) == \"HLK[\":\n",
    "    \n",
    "    clause = L.u(w, \"clause\")\n",
    "    \n",
    "    text_whole_clause = T.text(clause)\n",
    "    print(T.sectionFromNode(w), F.vt.v(w), F.vs.v(w), F.gn.v(w), F.nu.v(w), text_whole_clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MXpN6EJ_zKh"
   },
   "source": [
    "And of course, it can be important to export the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8RGHuc0AA3f"
   },
   "outputs": [],
   "source": [
    "hlk_dict = {}\n",
    "\n",
    "for w in F.otype.s(\"word\"):\n",
    "  if F.lex.v(w) == \"HLK[\":\n",
    "    clause = L.u(w, \"clause\")\n",
    "    bo, ch, ve = T.sectionFromNode(w)\n",
    "    text_whole_clause = T.text(clause)\n",
    "    hlk_list = [bo, ch, ve, F.vt.v(w), F.vs.v(w), F.gn.v(w), F.nu.v(w), text_whole_clause]\n",
    "    hlk_dict[w] = hlk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lbuPOuGHBWQr",
    "outputId": "baef1b67-73bf-4ea7-b653-e91483ebc47e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hlk_df = pd.DataFrame(hlk_dict).T\n",
    "hlk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkXQZXnzB-F7"
   },
   "outputs": [],
   "source": [
    "hlk_df.to_csv(\"query_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfjkkLSTEbsu"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download( \"hlk_dataset.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "book book=Samuel_I\n",
    "  clause\n",
    "    word sp=nmpr\n",
    "'''\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dead Sea Scrolls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XT6HDiPT84Zo"
   },
   "source": [
    "Now, we move to the DSS module. First the data are downloaded and loaded using the incantation, just like we did with the BHSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "colab_type": "code",
    "id": "k-P6T9rT80tr",
    "outputId": "b47145dd-001d-42fb-dbe6-5046a99db182"
   },
   "outputs": [],
   "source": [
    "from tf.app import use\n",
    "A = use('dss', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52UnEquiAhE6"
   },
   "source": [
    "Which object types do we have in this module?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.otype.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lXaahL6880yR",
    "outputId": "5e234403-199a-4e9a-b6cc-2814d856ea31"
   },
   "outputs": [],
   "source": [
    "object_count_dict = collections.defaultdict(int)\n",
    "\n",
    "for node in N():\n",
    "  object_count_dict[F.otype.v(node)] += 1\n",
    "  \n",
    "print(object_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OX1S_IKvBgtk"
   },
   "source": [
    "What are the names of the scrolls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "McW4PL_F804f",
    "outputId": "ed53268c-6871-4977-f8f6-ef87d5d03d59"
   },
   "outputs": [],
   "source": [
    "for scr in F.otype.s('scroll'):\n",
    "    scroll_name = T.scrollName(scr)\n",
    "    print(scroll_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scr in F.otype.s('scroll'):\n",
    "    scroll_name = T.scrollName(scr)\n",
    "    \n",
    "    if scroll_name == '1QS':\n",
    "        words = L.d(scr, 'word')\n",
    "        \n",
    "        for w in words:\n",
    "            print(w, F.lex.v(w) ,F.lexe.v(w), F.lexo.v(w), F.glex.v(w), F.glexe.v(w), F.glexo.v(w), F.biblical.v(w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZLBkIV1CFyk"
   },
   "source": [
    "Let's explore one scroll: 1QIsaa, the [Great Isaiah Scroll](https://en.wikipedia.org/wiki/Isaiah_Scroll)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iPGnqO1Dz9l"
   },
   "outputs": [],
   "source": [
    "for scr in F.otype.s('scroll'):\n",
    "    scroll = T.scrollName(scr)\n",
    "    \n",
    "    if scroll == \"1Qisaa\":\n",
    "        lines = L.d(scr, 'line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the results below with a [picture](http://dss.collections.imj.org.il/isaiah#1:1) of the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "AwM4CdAzD9XN",
    "outputId": "303f8886-c101-458d-e1a3-57bb2d3f9cd7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in lines[0:10]:\n",
    "    A.plain(l) # note that 1:1, 1:2, etc means the line on a column in the manuscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that this is the book of Isaiah, but where in the book of Isaiah (chapter, verse) can we find these lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = L.d(lines[0], 'word')\n",
    "for word in words:\n",
    "    print(F.book.v(word), F.chapter.v(word), F.verse.v(word), F.biblical.v(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scr in F.otype.s('scroll'):\n",
    "    if T.scrollName(scr) == '1QpHab':\n",
    "        words = L.d(scr, 'word')\n",
    "        \n",
    "        print(\"Pesher Habakkuk contains\", len(words), \"words.\")\n",
    "        \n",
    "        \n",
    "        for word in words:\n",
    "            print(F.biblical.v(word), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "beF639apIdOQ",
    "outputId": "bfefc954-d5ab-4185-bae8-e3d05f8701d2"
   },
   "outputs": [],
   "source": [
    "for l in lines[0:10]:\n",
    "  A.plain(l, withPassage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "ekSf9mFhI2Ss",
    "outputId": "f5120f1a-1b18-4465-f2e5-80cda23d66c7"
   },
   "outputs": [],
   "source": [
    "for l in lines[0:10]:\n",
    "  A.plain(l, fmt='text-source-extra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "p_Yi6R6PJDP-",
    "outputId": "326038c0-f6b8-491d-abd4-9d39b49bb825"
   },
   "outputs": [],
   "source": [
    "for l in lines[0:10]:\n",
    "  A.plain(l, fmt='text-trans-extra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "6p49sE5hJiEi",
    "outputId": "69adc538-0e30-4590-f35a-8e2f5ef0265f"
   },
   "outputs": [],
   "source": [
    "for l in lines[0:10]:\n",
    "  A.plain(l, fmt='layout-orig-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.pretty(lines[0], fmt='layout-orig-full', withNodes=False, lineNumbers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "HqOuj-CRMzAT",
    "outputId": "415cf938-78c1-4748-fb42-a401d9d6f885"
   },
   "outputs": [],
   "source": [
    "examplefragment = ('1Qisaa', '1')\n",
    "f = T.nodeFromSection(examplefragment)\n",
    "lines = L.d(f, otype='line')\n",
    "words = L.d(f, otype='word')\n",
    "signs = L.d(f, otype='sign')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some Search queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "line biblical=2\n",
    "\n",
    "'''\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "line \n",
    "  word vs=nifal nu=s\n",
    "    sign unc\n",
    "'''\n",
    "results = A.search(query)\n",
    "A.table(results, end=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "line \n",
    "  word book=Gen chapter=1\n",
    "\n",
    "'''\n",
    "results = A.search(query)\n",
    "A.table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "line\n",
    "  word gn=m gn2=f\n",
    "\n",
    "'''\n",
    "results = A.search(query)\n",
    "A.table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "line\n",
    "  sign cor=3\n",
    "\n",
    "'''\n",
    "results = A.search(query)\n",
    "A.table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "line\n",
    "  word gn=m vt=ptca\n",
    "  < word vs=qal\n",
    "\n",
    "'''\n",
    "results = A.search(query)\n",
    "A.table(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biblical scrolls in the DSS module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to see where biblical texts occur in the DSS. Suppose we want to know where all the places where Deuteronomy can be found in the DSS, and we want to compare those texts with the MT, how do we do that?\n",
    "\n",
    "Our strategy is as follows:\n",
    "\n",
    "1. We use the incantation for both the DSS and the BHSA, but we rename the classes F, L, and T for the DSS. With this step we prevent that they are overwritten.\n",
    "2. Then we iterate over all the scrolls. In the scrolls we iterate over all lines, and in each line, we iterate over each word.\n",
    "3. For each word in a line we check if it is marked with the biblical book Deuteronomy.\n",
    "4. If so, we retrieve which chapter and verse(s) (based on the BHSA) can be found in this line. \n",
    "5. Then we retrieve the text of the verse(s) in the MT and the DSS line and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "\n",
    "from tf.app import use\n",
    "A = use('dss', hoist=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fdss = F\n",
    "Ldss = L\n",
    "Tdss = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.app import use\n",
    "A = use('bhsa', hoist=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_dict = {'Genesis':      'Gen',\n",
    "             'Exodus':       'Ex',\n",
    "             'Leviticus':    'Lev',\n",
    "             'Numbers':      'Num',\n",
    "             'Deuteronomy':  'Deut',\n",
    "             'Joshua':       'Josh',\n",
    "             'Judges':       'Judg',\n",
    "             '1_Samuel':     '1Sam',\n",
    "             '2_Samuel':     '2Sam',\n",
    "             '1Kings':       '1Kgs',\n",
    "             '2_Kings':      '2Kgs',\n",
    "             'Isaiah':       'Is',\n",
    "             'Jeremiah':     'Jer',\n",
    "             'Ezekiel':      'Ezek',\n",
    "             'Hosea':        'Hos',\n",
    "             'Joel':         'Joel',\n",
    "             'Amos':         'Amos',\n",
    "             'Obadiah':      'Obad',\n",
    "             'Jonah':        'Jonah',\n",
    "             'Micah':        'Mic',\n",
    "             'Nahum':        'Nah',\n",
    "             'Habakkuk':     'Hab',\n",
    "             'Zephaniah':    'Zeph',\n",
    "             'Haggai':       'Hag',\n",
    "             'Zechariah':    'Zech',\n",
    "             'Malachi':      'Mal',\n",
    "             'Psalms':       'Ps',\n",
    "             'Job':          'Job',\n",
    "             'Proverbs':     'Prov',\n",
    "             'Ruth':         'Ruth',\n",
    "             'Song_of_songs':'Song',\n",
    "             'Ecclesiastes': 'Eccl',\n",
    "             'Lamentations': 'Lam',\n",
    "             'Daniel':       'Dan',\n",
    "             'Ezra':         'Ezra',\n",
    "             '2_Chronicles': '2Chr'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE A BOOK FROM THE LEFT COLUMN IN THE book_dict AND CHOOSE A CHAPTER\n",
    "MT_BOOK = 'Habakkuk'\n",
    "CHAPTER = 2\n",
    "\n",
    "DSS_BOOK = book_dict[MT_BOOK]\n",
    "\n",
    "# STEP 2\n",
    "for scr in Fdss.otype.s('scroll'):\n",
    "    lines = Ldss.d(scr, 'line')\n",
    "    for line in lines:\n",
    "        words = Ldss.d(line, 'word')\n",
    "        biblical_book_per_word = [Fdss.book.v(w) for w in words]\n",
    "\n",
    "# STEP 3    \n",
    "        if DSS_BOOK in biblical_book_per_word:\n",
    "            scr_name = Tdss.scrollName(scr)\n",
    "# STEP 4\n",
    "            chapter = set([Fdss.chapter.v(w) for w in words])\n",
    "            verses = set([int(Fdss.verse.v(w)) for w in words])\n",
    "            \n",
    "# STEP 5\n",
    "            try:\n",
    "                ch = int(list(chapter)[0])\n",
    "                if ch == CHAPTER:\n",
    "                    for verse in verses:\n",
    "                        section = (MT_BOOK, ch, verse)\n",
    "                        mt_verse = T.nodeFromSection(section)\n",
    "                        print(section)\n",
    "                        mt_verse_words = L.d(mt_verse, 'word')\n",
    "                        mt_text = ' '.join([F.g_cons_utf8.v(mt_w) for mt_w in mt_verse_words])\n",
    "                        print('BHSA', MT_BOOK, ch, verse, mt_text)\n",
    "                        print(scr_name, DSS_BOOK, ch, verse, Tdss.text(words))\n",
    "                        print('\\n')\n",
    "            except:\n",
    "                print(scr_name, list(chapter)[0])\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dhbs_01_10_2019.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
